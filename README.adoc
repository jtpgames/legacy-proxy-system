Legacy Proxy Pattern Experiments
:toc:
:toc-placement!:

This repository contains experimental scripts and automation tools for research on the Legacy Proxy Pattern, investigating its implementation, performance characteristics, and practical applications in software modernization.

toc::[]

== Overview
TODO

== Requirements

=== System Requirements

To enhance the reliability of our experimental results and ensure they robustly support our claims, we conducted the experiments across various hardware and software configurations. The specific configurations utilized by the authors include:

==== Configuration 1

* MacOS 10.15
* Homebrew package manager

==== Configuration 2
Virtual machine running with

* CPU: 16 vCPUs
* RAM: 32GB
* OS: Ubuntu 24.04 LTS 64-bit (newer OS versions are untested)

on the following hardware:
* CPU: 2x Intel® Xeon® Processor E5-2690 @ 2,90 GHz × 8

=== Dependencies

==== Bash Installation (MacOS)

The scripts require Bash 5.0 or higher. Install it via Homebrew:

[source,bash]
----
# Install latest bash version
brew install bash

# Replace buildin version of bash with the new version of bash
echo 'alias bash="/opt/homebrew/bin/bash"' >> ~/.zshrc
----

==== Bash Installation (Ubuntu)

The scripts require Bash 5.0 or higher. Ubuntu 24.04 comes with this version preinstalled.

==== Additional tools

[source,bash]
----
# Install ripgrep as a fast grep alternative
brew install ripgrep

----

[source,bash]
----
# -- From docker documentation --
# Add Docker's official GPG key:
sudo apt-get update
sudo apt-get install ca-certificates curl
sudo install -m 0755 -d /etc/apt/keyrings
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
sudo chmod a+r /etc/apt/keyrings/docker.asc

# Add the repository to Apt sources:
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release && echo "${UBUNTU_CODENAME:-$VERSION_CODENAME}") stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update
--

sudo apt-get install -y software-properties-common build-essential bc ripgrep git docker-compose docker-ce screen python3.12-venv python3.12-dev

sudo groupadd docker
sudo usermod -aG docker $USER
----

== Troubleshooting

=== Network Delays Between Load Tester and Proxy Services

==== Problem Description

During load testing, intermittent delays of approximately 15 seconds were observed between the load tester sending requests and the first proxy service (ars-comp-1) receiving them. While the proxy services themselves processed requests efficiently (typically 40-50ms), these network-layer delays significantly impacted overall response times.

==== Analysis Process

1. **Request Tracing**: By analyzing load tester logs and proxy logs with matching request IDs, we confirmed that:
   - Load tester sends request at timestamp A
   - Proxy receives same request at timestamp A + 15 seconds
   - Proxy processes request normally in ~40ms

2. **Infrastructure Investigation**: Initial suspicions focused on:
   - Podman user-mode networking performance on macOS
   - FastAPI/Uvicorn configuration issues
   - Container resource limitations

3. **Root Cause Discovery**: The issue was traced to TCP listen queue overflow behavior:
   - System setting `net.ipv4.tcp_abort_on_overflow = 0` causes silent packet drops
   - When the listen queue is full, SYN packets are dropped rather than rejected
   - Clients experience exponential backoff delays (3s, 6s, 12s...) waiting for retransmission

==== Solution

Modify the TCP behavior in the Podman machine to immediately reject connections when the listen queue is full, rather than causing delays:

[source,bash]
----
# Temporary fix (active until VM restart)
podman machine ssh sudo sysctl -w net.ipv4.tcp_abort_on_overflow=1

# Permanent fix (persists across reboots)
podman machine ssh "echo 'net.ipv4.tcp_abort_on_overflow = 1' | sudo tee -a /etc/sysctl.conf"

# Verify the change
podman machine ssh sysctl net.ipv4.tcp_abort_on_overflow
----

==== Additional TCP Optimizations

For improved performance under high connection loads, apply these additional TCP optimizations:

[source,bash]
----
# Apply optimizations immediately
podman machine ssh "sudo sysctl -w net.core.netdev_max_backlog=2000"
podman machine ssh "sudo sysctl -w net.ipv4.tcp_max_syn_backlog=2048"
podman machine ssh "sudo sysctl -w net.ipv4.tcp_fin_timeout=30"
podman machine ssh "sudo sysctl -w net.ipv4.ip_local_port_range='1024 61000'"

# Make settings persistent across reboots
podman machine ssh "echo 'net.core.netdev_max_backlog = 2000' | sudo tee -a /etc/sysctl.conf"
podman machine ssh "echo 'net.ipv4.tcp_max_syn_backlog = 2048' | sudo tee -a /etc/sysctl.conf"
podman machine ssh "echo 'net.ipv4.tcp_fin_timeout = 30' | sudo tee -a /etc/sysctl.conf"
podman machine ssh "echo 'net.ipv4.ip_local_port_range = 1024 61000' | sudo tee -a /etc/sysctl.conf"
----

**Settings Explanation:**

* `net.core.netdev_max_backlog = 2000`: Increases network device packet queue size (default: 1000)
* `net.ipv4.tcp_max_syn_backlog = 2048`: Expands SYN packet backlog (default: 256)
* `net.ipv4.tcp_fin_timeout = 30`: Reduces connection cleanup time (default: 60 seconds)
* `net.ipv4.ip_local_port_range = 1024 61000`: Expands available port range for outbound connections

==== Docker Implementation

The TCP optimizations must also be applied at the container level, as Docker/Podman containers use separate network namespaces that do not inherit host-level sysctl settings. Both `docker-compose-legacy.yml` and `docker-compose-ng.yml` have been configured with container-level TCP optimizations.

**Container-Level Settings:**

All Python-based proxy containers now include the following sysctl configurations:

[source,yaml]
----
sysctls:
  - net.ipv4.tcp_max_syn_backlog=2048
  - net.ipv4.tcp_fin_timeout=30
  - net.ipv4.ip_local_port_range=1024 61000
  - net.ipv4.tcp_abort_on_overflow=1
----

**Note:** The `net.core.netdev_max_backlog` setting cannot be applied at the container level as it requires host-level privileges. This optimization remains effective at the Podman machine level for host-to-container traffic.

**Verification:**

To verify that container-level TCP settings are applied correctly:

[source,bash]
----
# Start a test container
cd python && docker-compose -f docker-compose-legacy.yml up -d ars-comp-1-1

# Check settings inside the container
docker exec <container-id> cat /proc/sys/net/ipv4/tcp_max_syn_backlog
docker exec <container-id> cat /proc/sys/net/ipv4/tcp_abort_on_overflow

# Clean up
docker-compose -f docker-compose-legacy.yml down
----

==== Fedora CoreOS Compatibility

The Podman machine environment uses Fedora CoreOS, which provides several advantages for TCP performance optimization:

**System Information:**
- **OS**: Fedora CoreOS 40.20241019.3.0
- **Kernel**: 6.11.3-200.fc40.aarch64
- **Architecture**: Container-optimized minimal OS

**Performance Benefits:**

* **Modern TCP Stack**: Kernel 6.11.3 includes latest TCP improvements and RFC implementations
* **Container-Optimized**: Designed specifically for containerized workloads with tuned networking defaults
* **Minimal Overhead**: Reduced background processes compared to desktop distributions
* **Immutable Design**: Persistent sysctl configurations survive reboots reliably

**Network Stack Features:**

[source,bash]
----
# Current congestion control (can be optimized further)
podman machine ssh "sysctl net.ipv4.tcp_congestion_control"
# Output: net.ipv4.tcp_congestion_control = cubic

# Kernel version verification
podman machine ssh "uname -r"
# Output: 6.11.3-200.fc40.aarch64
----

**Note**: The modern kernel and container-focused design of Fedora CoreOS provides an ideal foundation for the TCP optimizations implemented in this project. All host-level and container-level settings are fully compatible and effective.

**References:**

_Note: The following references were AI-generated and have not been fully reviewed for accuracy._

* Fedora CoreOS Documentation: https://docs.fedoraproject.org/en-US/fedora-coreos/[Official Fedora CoreOS Guide]
* Container optimization design: https://github.com/coreos/fedora-coreos-docs[Fedora CoreOS Architecture]
* Linux kernel 6.11 TCP improvements: https://kernelnewbies.org/Linux_6.11[Linux 6.11 Release Notes]
* Immutable OS benefits: https://ostree.readthedocs.io/[OSTree Documentation]

==== Alternative Solutions

If connection errors occur after the above change, consider increasing the application-level backlog:

[source,python]
----
# In FastAPI/Uvicorn applications
uvicorn.run(app, host=host, port=port, backlog=8192, ...)
----

==== References

_Note: The following references were AI-generated and have not been fully reviewed for accuracy._

* Linux TCP implementation: https://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt[tcp_abort_on_overflow documentation]
* TCP listen queue behavior: Stevens, W. Richard. "TCP/IP Illustrated, Volume 1: The Protocols." Addison-Wesley, 2011.
* Uvicorn configuration: https://www.uvicorn.org/settings/#socket-bind[Uvicorn Settings Documentation]
* TCP optimization for high-performance servers: https://www.digitalocean.com/community/questions/max-number-of-concurrent-tcp-connections-to-droplet[DigitalOcean TCP Connection Limits]
* Linux network performance tuning: https://fasterdata.es.net/host-tuning/linux/[ESnet Linux Tuning Guide]
* TCP parameter tuning: Carder, Bradley. "Linux Network Performance Tuning." Linux Journal, 2016.
* High-performance networking: https://blog.packagecloud.io/monitoring-tuning-linux-networking-stack-receiving-data/[Linux Networking Stack Tuning]

== Usage

=== HTTP/2 Support with Granian

The proxy services in this project support HTTP/2 cleartext (h2c) connections through Granian, which provides performance benefits over HTTP/1.1 including request multiplexing and header compression.

==== Running Services with HTTP/2

The Docker Compose configurations (`docker-compose-legacy.yml` and `docker-compose-ng.yml`) already use the `start_python_app_with_tc.sh` script with the `--use-granian` flag to run all proxy services with HTTP/2 support:

[source,yaml]
----
# Services in docker-compose files use this format:
command: ./start_python_app_with_tc.sh ars_comp_1_proxy.py --use-granian
----

When you run the Docker Compose setup, all proxy services automatically start with Granian using HTTP/2 instead of the default Uvicorn with HTTP/1.1. The `--http 2` flag is automatically passed to Granian in the script.

To manually run a service with HTTP/2 support outside of Docker Compose:

[source,bash]
----
# Run a proxy service with HTTP/2 support using Granian
./start_python_app_with_tc.sh ars_comp_1_proxy.py --use-granian
----

==== Client-Side HTTP/2 Configuration

When httpx clients communicate with HTTP/2 services, they must be configured to use HTTP/2 exclusively. This is achieved by setting both `http2=True` and `http1=False` parameters when constructing the client:

[source,python]
----
import httpx

# For synchronous clients
client = httpx.Client(http2=True, http1=False)

# For asynchronous clients
async_client = httpx.AsyncClient(http2=True, http1=False)
----

**Important**: Without the `http1=False` parameter, httpx may attempt HTTP/1.1 negotiation, which can result in protocol errors like "illegal request line" when communicating with HTTP/2 services.

==== USE_HTTP_2 Environment Variable

The httpx clients in proxy services can be configured to use HTTP/2 via the `USE_HTTP_2` environment variable. This provides fine-grained control over which client connections use HTTP/2:

[source,yaml]
----
# In docker-compose files
environment:
  - USE_HTTP_2=true  # Enable HTTP/2 for httpx client
----

When `USE_HTTP_2` is set to `true`, `1`, or `yes`, the httpx client will be configured with:
* `http2=True` - Enable HTTP/2 protocol
* `http1=False` - Disable HTTP/1.1 to force HTTP/2 cleartext (h2c)

This setting controls the **client-side** HTTP protocol used for outbound requests, independent of how the service itself accepts incoming connections (which is controlled by the `--use-granian` flag).

==== Request Flow Diagrams

**Baseline Architecture:**

[source]
----
┌──────────────┐                 ┌─────────────────┐                 ┌─────────────────┐                 ┌──────────────┐
│   Locust     │    HTTP/2 or    │  ars-comp-1     │    HTTP/2 or    │  ars-comp-2     │     HTTP/1.1    │     RAST     │
│ Load Tester  │────HTTP/1.1────▶│  (ARS SRV 1)    │────HTTP/1.1────▶│  (ARS SRV 2)    │────(forced)────▶│  Simulator   │
│              │  (USE_HTTP_2)   │                 │  (USE_HTTP_2)   │                 │                 │              │
└──────────────┘                 └─────────────────┘                 └─────────────────┘                 └──────────────┘
     │                                   │                                   │                                   │
     │                                   │                                   │                                   │
   Granian                            Granian                            Granian                               Ktor
  (--use-granian)                    (--use-granian)                    (--use-granian)                       (HTTP/1.1)
   HTTP/2 h2c                        HTTP/2 h2c                         HTTP/2 h2c                          
   or Uvicorn                        or Uvicorn                         or Uvicorn                          
   HTTP/1.1                          HTTP/1.1                           HTTP/1.1                            
                                                                                                           
   httpx Client                      httpx Client                      httpx Client                        
   HTTP/2 or HTTP/1.1                HTTP/2 or HTTP/1.1                HTTP/1.1 (forced)                   
   (USE_HTTP_2)                      (USE_HTTP_2)                      (ignores USE_HTTP_2)
----

**Refactored Architecture with LPS:**

[source]
----
┌──────────────┐                 ┌─────────────────┐                 ┌─────────────────┐      ┌──────────┐      ┌─────────────────┐                 ┌─────────────────┐                 ┌──────────────┐
│   Locust     │    HTTP/2 or    │  ars-comp-1     │    HTTP/2 or    │ legacy-proxy-1  │      │  MQTT    │      │ legacy-proxy-2  │    HTTP/2 or    │  ars-comp-2     │     HTTP/1.1    │     RAST     │
│ Load Tester  │────HTTP/1.1────▶│  (ARS SRV 1)    │────HTTP/1.1────▶│  (HTTP→MQTT)    │─────▶│  Broker  │─────▶│  (MQTT→HTTP)    │────HTTP/1.1────▶│  (ARS SRV 2)    │────(forced)────▶│  Simulator   │
│              │  (USE_HTTP_2)   │                 │  (USE_HTTP_2)   │                 │ QoS2 │ MQTTv5   │ QoS2 │                 │  (USE_HTTP_2)   │                 │                 │              │
└──────────────┘                 └─────────────────┘                 └─────────────────┘      └──────────┘      └─────────────────┘                 └─────────────────┘                 └──────────────┘
     │                                   │                                   │                                           │                                   │                                   │
     │                                   │                                   │                                           │                                   │                                   │
   Granian                            Granian                            Granian                                    No Server                          Granian                                 Ktor
   (--use-granian)                   (--use-granian)                   (--use-granian)                             (MQTT Client)                      (--use-granian)                         (HTTP/1.1)
   HTTP/2 h2c                        HTTP/2 h2c                        HTTP/2 h2c                                  aiomqtt                            HTTP/2 h2c                          
   or Uvicorn                        or Uvicorn                        or Uvicorn                                  MQTTv5                             or Uvicorn                          
   HTTP/1.1                          HTTP/1.1                          HTTP/1.1                                                                       HTTP/1.1                            
                                                                                                                   httpx Client                                                            
   httpx Client                      httpx Client                      aiomqtt                                     HTTP/2 or HTTP/1.1                 httpx Client                        
   HTTP/2 or HTTP/1.1                HTTP/2 or HTTP/1.1                MQTTv5                                      (USE_HTTP_2)                       HTTP/1.1 (forced)                   
   (USE_HTTP_2)                      (USE_HTTP_2)                      (publishes to MQTT)                                                            (ignores USE_HTTP_2)
----

**Protocol Notes:**

* **Server-side protocol** (incoming): Controlled by `--use-granian` flag (HTTP/2) or default Uvicorn (HTTP/1.1)
* **Client-side protocol** (outgoing): Controlled by `USE_HTTP_2` environment variable in httpx clients
* **ars-comp-2 exception**: Always uses HTTP/1.1 for RAST communication regardless of `USE_HTTP_2` setting
* **MQTT Bridge**: legacy-proxy-2 is an MQTT subscriber that initiates HTTP requests (no incoming HTTP server)

**Files Configured for HTTP/2:**

* `python/ars_comp_1_proxy.py` - Uses HTTP/2 for downstream requests (configured via `USE_HTTP_2`)
* `python/ars_comp_2_proxy.py` - **HTTP/2 DISABLED**: Uses HTTP/1.1 only for downstream requests to RAST simulator (hardcoded, does not respect `USE_HTTP_2`)
* `python/mqtt/legacy_proxy_2.py` - Uses HTTP/2 for downstream requests (configured via `USE_HTTP_2`)
* `locust_scripts/common/common_locust.py` - Load test client configured for HTTP/2 connections (configured via `USE_HTTP_2`)

== Cloning
If you want to work on the current version of the project, clone the repository and pull all git submodules with the following command. 

[source]
----
git clone https://github.com/jtpgames/legacy-proxy-pattern.git && cd legacy-proxy-pattern && ./pull_all_submodules.sh
----

== License

This project is licensed under the BSD License - see the LICENSE file for details.

== AI Disclosure

This project utilized Warp AI (warp.dev) as an AI assistant in its development process. Specifically:

* **Documentation**: Warp AI was used to help write and improve portions of this README.adoc file, including troubleshooting guides and technical explanations.
* **Code Development**: Warp AI served as a coding assistant for developing and debugging bash and Python scripts.

While AI tools provided valuable assistance, all code and documentation have been reviewed, tested, and validated by the author. The final implementation decisions, architectural choices, and experimental design originate from the author.


